{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how Recommender/Recommendation Systems have played an integral parts in the success of Amazon (Books, Items), Pandora/Spotify (Music), Google (News, Search), YouTube (Videos), etc.  For Amazon, these systems bring more than 30% of their total revenues. For Netflix service, 75% of movies that people watch are based on some sort of recommendation.\n",
    "\n",
    "> The goal of Recommendation Systems is to find what is likely to be of interest to the user. This enables organizations to offer a high level of personalization and customer-tailored services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Main Types\n",
    "\n",
    "- non-personalized\n",
    "- content-based\n",
    "- collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Personalized Recommendations\n",
    "\n",
    "![screenshot of youtube's homepage](images/youtube-nonpersonalizedrecommendations.png)\n",
    "\n",
    "YouTube is notorious for putting non-personalized content on their homepage (although they tailor recommendations in other places)\n",
    "\n",
    "These recommendations are based purely on the popularity of the item!\n",
    "\n",
    "#### Advantages\n",
    "- Super easy (computationally and for the user to understand)\n",
    "- Items are usually popular for a reason\n",
    "- No cold-start issue\n",
    "\n",
    "#### Disadvantages\n",
    "- Not personalized\n",
    "- New items won’t gain traction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based\n",
    "\n",
    "![screenshot found online of someone's 'made for you' recommendations from spotify](images/spotify-contentrecommendations.png)\n",
    "\n",
    "[Image Source](https://www.howtogeek.com/393291/already-a-spotify-fan-here-are-6-new-features-you-might-have-missed/)\n",
    "\n",
    "Content-based recommendations are based on the properties/attributes of the items, where the items you've rated highly (or, in Spotify's case, listened to recently or often) are then compared against the properties/attributes of other items, and those items are then recommended if they're considered 'similar'.\n",
    "\n",
    "What items are 'similar'? Depends on your similarity metric:\n",
    "\n",
    "![similarity metrics comparison](images/similaritymetrics.png)\n",
    "\n",
    "[Image Source: \"What Similarity Metric Should You Use for Your Recommendation System?](https://medium.com/bag-of-words/what-similarity-metric-should-you-use-for-your-recommendation-system-b45eb7e6ebd0) <- useful reading!\n",
    "\n",
    "Those are just 3 examples, there are others (Jaccard index, Euclidian similarity) - but the point is you take some mathematical understanding of the items and find which ones are 'nearby' in some sense.\n",
    "\n",
    "#### Advantages:\n",
    "- Easy and transparent\n",
    "- No cold start issue\n",
    "- Recommend items to users with unique tastes\n",
    "\n",
    "#### Disadvantages:\n",
    "- Requires some type of tagging of items\n",
    "- Overspecialization to certain types of items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "![collaborative filtering utility matrix example](images/collaborativefiltering.png)\n",
    "\n",
    "[Image Source](https://www.incubegroup.com/blog/recommender-system-for-private-banking/)\n",
    "\n",
    "Use both User and Item data! Use past behavior of many users (how they've rated many items) to find similarities either between users or between items (either user-based or item-based) to recommend new things.\n",
    "\n",
    "We build a Utility/Rating Matrix to capture many users' ratings of many different items - a matrix that, in practice, tends to be quite _sparse_ (see all the blanks in just this tiny example above).\n",
    "\n",
    "Then, we use **_MATH_** (namely, matrix factorization) to fill in those blanks, based upon similar users' ratings of similar items.\n",
    "\n",
    "More specifically, it finds factor matrices which result in the ratings it has - decomposing the actual Utility Matrix into component pieces that explain it. These component pieces, matrices themselves, can be thought of as 'latent' or 'inherent' features of the items and users! The math then comes in, as we calculate the dot products in order to arrive at our predicted ratings.'\n",
    "\n",
    "<img src=\"images/matrixfactorization.png\" alt=\"matrix factorization image, showing the factor matrices\" width=700>\n",
    "\n",
    "[Image Source](https://medium.com/@connectwithghosh/simple-matrix-factorization-example-on-the-movielens-dataset-using-pyspark-9b7e3f567536)\n",
    "\n",
    "A bit more on Matrix Factorization, from Google's Recommendations Systems crash course: https://developers.google.com/machine-learning/recommendation/collaborative/matrix\n",
    "\n",
    "#### Advantages:\n",
    "- Personalized. You’re special!\n",
    "\n",
    "#### Disadvantages:\n",
    "- Can require a lot of computation, especially as these matrices get larger\n",
    "- Cold start: need to have a lot of ratings to be worthwhile\n",
    "- Popularity Bias: biased towards items that are popular. May not capture people’s unique tastes.\n",
    "\n",
    "Matrix factorization methods include Singular Value Decomposition (SVD) and Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll note that there are differences between _explicit_ and _implicit_ ratings.\n",
    "\n",
    "- **_Explicit_** data is gathered from users when we ask a user to rate an item on some scale\n",
    "    - Pros: concrete rating system, can assume users actually feel the way they input and thus can extrapolate from those preferences\n",
    "    - Cons: not all users might input their preferences\n",
    "- **_Implicit_** data is gathered from users without their direct input - a system logs the actions of a user\n",
    "    - Pros: Easier to collect automatically, thus have more data from more users without those users needing to go through extra steps\n",
    "    - Cons: More difficult to work with - how do we know what actions imply preference?\n",
    "    \n",
    "[insert comment about y'all filling out surveys here]\n",
    "\n",
    "[Resource](https://www.cs.carleton.edu/cs_comps/0607/recommend/recommender/collaborativefiltering.html#:~:text=Implicit%20Data%20Collection,system%20has%20to%20collect%20data.&text=Explicit%20data%20gathering%20is%20easy,data%20to%20predict%20future%20ratings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now, in code!\n",
    "\n",
    "### Reading in the data and simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Source:\n",
    "\n",
    "https://www.kaggle.com/rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, round 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data and check it out\n",
    "df = pd.read_csv('data/ratings.csv') \n",
    "print(df.shape) \n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also get the data straight from the surprise library we'll be using\n",
    "\n",
    "# from surprise import Dataset\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "# df = pd.read_csv('~/.surprise_data/ml-100k/ml-100k/u.data',\n",
    "#             sep='\\t', header=None)\n",
    "# df = df.rename(columns={0: 'user', 1: 'item', 2: 'rating', 3: 'timestamp'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check value_counts\n",
    "ratings = df['rating'].value_counts()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sorted = dict(zip(ratings.index, ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution in matplotlib\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(ratings_sorted.keys(), ratings_sorted.values(), width=.4)\n",
    "plt.xticks(np.arange(0, 5.1, step=0.5))\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"# of Ratings\")\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of users: \", df.userId.nunique()) \n",
    "print(\"Average Number of Reviews per User: \", df.shape[0]/df.userId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = df['userId'].value_counts()\n",
    "ratings_per_user = sorted(list(zip(ratings_per_user.index, ratings_per_user)))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar([r[0] for r in ratings_per_user], [r[1] for r in ratings_per_user])\n",
    "plt.xlabel(\"User ID\")\n",
    "plt.ylabel(\"# of Reviews\")\n",
    "plt.title(\"Number of Reviews per User\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of movies: \", df.movieId.nunique())\n",
    "print(\"Average Number of Reviews per Movie: \", df.shape[0]/df.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the movie IDs with the most ratings\n",
    "df['movieId'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_movie = df['movieId'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(ratings_per_movie, bins=50)\n",
    "plt.xlabel(\"# of Reviews\")\n",
    "plt.ylabel(\"# of Movies\")\n",
    "plt.title(\"Distribution of the Number of Ratings Per Movie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition using Surprise\n",
    "\n",
    "Written by Yish, thanks <3\n",
    "\n",
    "One of the easiest libraries to use for recommendation systems is Surprise, which stands for **Simple Python Recommendation System Engine**. Here, we'll code a recommendation system using the Surprise Library's Singular Value Decomposition (SVD) algorithm.\n",
    "\n",
    "To read more about Surprise's SVD implementation, and its hyperparameters:\n",
    "https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need the surprise library\n",
    "# !pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, round 2\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Surprise, we only need three columns from the dataset\n",
    "data = df[['userId', 'movieId', 'rating']]\n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "data = Dataset.load_from_df(data, reader=reader)\n",
    "\n",
    "# note - if you loaded this data up straight from surprise earlier\n",
    "# you won't need to do this - data will already be a surprise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SVD and fit the trainset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our predictions out and score our model\n",
    "predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a look at the first 10 rows of our test set\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of users: \", df.userId.nunique()) \n",
    "print(\"Number of movies: \", df.movieId.nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's predict for a specific user/item!\n",
    "user = 5\n",
    "item = 141\n",
    "svd.predict(user, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Models? More Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise has some basic algorithms - like `BaselineOnly`, which predicts a baseline estimate for a given user an item.\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showcasing the cross_validate function as well \n",
    "cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "\n",
    "Plus there are always neighbors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNNBasic().fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the nearest neighbors to an item\n",
    "KNN_model.get_neighbors(iid=item, k=1) # using same item as earlier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
