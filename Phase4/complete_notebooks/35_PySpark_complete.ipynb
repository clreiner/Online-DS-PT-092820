{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_cd_YKidmcH"
      },
      "source": [
        "# Installing PySpark on Google Colab\n",
        "\n",
        "Special thanks to my colleagues Jeff & James for content in this notebook <3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIyBO-9sCxD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1be113c-0b19-40e9-a4dc-bd4b911a9f24"
      },
      "source": [
        "!apt update"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Waiting for headers] [Waiting for headers] [Conn\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Waiting for headers] [Waiting for headers] [Conn\u001b[0m\r                                                                               \rGet:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Waiting for headers] [6 InRelease 0 B/88.7 kB 0%\u001b[0m\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Waiting for headers] [6 InRelease 14.2 kB/88.7 k\u001b[0m\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (105 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22vJMUf5CxzI"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crqUuL1tC31T"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsOcaPcRC6gK"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scohCVbjhIH4"
      },
      "source": [
        "# Resilient Distributed Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzG2AoAQgx-B"
      },
      "source": [
        "Resilient Distributed Datasets (RDD) are fundamental data structures of Spark. An RDD is essentially the Spark representation of a set of data, spread across multiple machines, with APIs to let you act on it.\n",
        "\n",
        "Use an RDD when:\n",
        "[(quoted from databricks)](https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html)\n",
        "\n",
        "- you want low-level transformation and actions and control on your dataset;\n",
        "- your data is unstructured, such as media streams or streams of text;\n",
        "- you want to manipulate your data with functional programming constructs than domain specific expressions;\n",
        "- you donâ€™t care about imposing a schema, such as columnar format, while processing or accessing data attributes by name or column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEOwsmcaryGP"
      },
      "source": [
        "RDDs have 2 operations that you can perform on them:\n",
        "- Transformations (create a new RDD)\n",
        "- Actions (return results)\n",
        "\n",
        "Note: transformations are lazy operators, they won't actually perform the transformation until an action is performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "131F8OBH-DiD"
      },
      "source": [
        "import pyspark"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLvUrYborxEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35dceaab-c278-47e5-a9eb-fa25fc62c3f7"
      },
      "source": [
        "# create a new RDD \n",
        "nums = list(range(1,1001))\n",
        "\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "\n",
        "rdd = sc.parallelize(nums, numSlices=10)\n",
        "rdd.getNumPartitions()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkC9D1QauUWa"
      },
      "source": [
        "#### Examples of Actions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlNSWFUxw9HR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290818c7-eb58-4d98-b391-34c2f29ce1d0"
      },
      "source": [
        "# first\n",
        "rdd.first()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzTPNXu_xPHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7860ffb-f2fb-4a10-be86-618050b3c1e0"
      },
      "source": [
        "# take\n",
        "rdd.take(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9AJBLs7xV-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269bb593-80dd-45e8-cfe9-010fa098cddb"
      },
      "source": [
        "# collect\n",
        "rdd.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999,\n",
              " 1000]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKfFlbTIxi7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43b0b12-d4b6-431e-f12c-abe7cf933387"
      },
      "source": [
        "# grab first partition using glom\n",
        "rdd.glom().collect()[3]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSs7jI9tIrZX",
        "outputId": "e4e8bdc9-9dcc-47c8-8feb-8e7c14e7a0f1"
      },
      "source": [
        "print(type(rdd))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.rdd.RDD'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNQADZFRv-aJ"
      },
      "source": [
        "#### Examples of Transformations\n",
        "- map\n",
        "- filter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTDUSkbYxwgN"
      },
      "source": [
        "# map\n",
        "# use a lambda to return x+1 if x is even, else just return x\n",
        "even_rdd = rdd.map(lambda x: x + 1 if x % 2 == 0 else x)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boCO3RMgxwpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd859f8-2d11-464d-9494-18c62e5bb7c0"
      },
      "source": [
        "even_rdd.take(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 3, 5, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwv1yHcAyRmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "e730e457-41b6-4c4e-b66b-ba4008dc4dcc"
      },
      "source": [
        "# now let's try to just return even results\n",
        "rdd.map(lambda x: x if x % 2 == 0)\n",
        "# can't really use a map for this..."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-100a67edae21>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    rdd.map(lambda x: x if x % 2 == 0)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZrYWGUEyoBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a2ae71-e7ba-47a4-fe04-9c1be2502c21"
      },
      "source": [
        "# try with filter now\n",
        "only_evens = rdd.filter(lambda x: x % 2 == 0)\n",
        "only_evens.take(10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBJchDwVzE-U"
      },
      "source": [
        "# stop your pyspark context instance\n",
        "# can't have multiple connections at once!\n",
        "sc.stop()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJh_wnqVhZ9R"
      },
      "source": [
        "# Spark DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo8LpYauxdoC"
      },
      "source": [
        "Dataframes in PySpark are the distributed collection of structured or semi-structured data. This data in Dataframe is stored in rows under named columns which is similar to the relational database tables or excel sheets. \n",
        "\n",
        "Use a Dataframe when:\n",
        "[(also quoted from databricks)](https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html)\n",
        "\n",
        "- you want rich semantics, high-level abstractions, and domain specific APIs, use DataFrame\n",
        "- your processing demands high-level expressions, filters, maps, aggregation, averages, sum, SQL queries, columnar access and use of lambda functions on semi-structured data, use DataFrame\n",
        "- you want higher degree of type-safety at compile time, want typed JVM objects, take advantage of Catalyst optimization, and benefit from Tungstenâ€™s efficient code generation, use Dataset;\n",
        "- you want unification and simplification of APIs across Spark Libraries, use DataFrame or Dataset;\n",
        "- If you are a R user, use DataFrames.\n",
        "- If you are a Python user, use DataFrames and resort back to RDDs if you need more control.\n",
        "\n",
        "Note: Machine learning algorithms are run on DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU2EAqWwHKJE"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4YRBOoJHMPf"
      },
      "source": [
        "spark = SparkSession.builder.master('local').getOrCreate()"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cCAlDu9j8wI"
      },
      "source": [
        "Need to upload data to access here!\n",
        "\n",
        "Link: https://www.kaggle.com/usdot/flight-delays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EEuVOh5HUzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db90ba76-f522-4b50-e763-8e82ec65d1a0"
      },
      "source": [
        "# reading in pyspark df\n",
        "spark_df = spark.read.csv('/flights.csv', header='true', inferSchema='true')\n",
        "\n",
        "# observing the datatype of df\n",
        "type(spark_df)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hos2Ek_xxvgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0369d701-e82b-43ca-e231-8cdb7fd8a82e"
      },
      "source": [
        "# number of rows\n",
        "print(spark_df.count())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5819079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhMZVKjR0PRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8338666-b54e-403d-d034-1ddfe451f168"
      },
      "source": [
        "# number of columns\n",
        "print(len(spark_df.columns))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj6xiwvS0VFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c6b70c-8e6e-4c5e-edc0-a3559cd8cb52"
      },
      "source": [
        "# check first five rows v1\n",
        "spark_df.take(5)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AS', FLIGHT_NUMBER=98, TAIL_NUMBER='N407AS', ORIGIN_AIRPORT='ANC', DESTINATION_AIRPORT='SEA', SCHEDULED_DEPARTURE=5, DEPARTURE_TIME=2354, DEPARTURE_DELAY=-11, TAXI_OUT=21, WHEELS_OFF=15, SCHEDULED_TIME=205, ELAPSED_TIME=194, AIR_TIME=169, DISTANCE=1448, WHEELS_ON=404, TAXI_IN=4, SCHEDULED_ARRIVAL=430, ARRIVAL_TIME=408, ARRIVAL_DELAY=-22, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AA', FLIGHT_NUMBER=2336, TAIL_NUMBER='N3KUAA', ORIGIN_AIRPORT='LAX', DESTINATION_AIRPORT='PBI', SCHEDULED_DEPARTURE=10, DEPARTURE_TIME=2, DEPARTURE_DELAY=-8, TAXI_OUT=12, WHEELS_OFF=14, SCHEDULED_TIME=280, ELAPSED_TIME=279, AIR_TIME=263, DISTANCE=2330, WHEELS_ON=737, TAXI_IN=4, SCHEDULED_ARRIVAL=750, ARRIVAL_TIME=741, ARRIVAL_DELAY=-9, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='US', FLIGHT_NUMBER=840, TAIL_NUMBER='N171US', ORIGIN_AIRPORT='SFO', DESTINATION_AIRPORT='CLT', SCHEDULED_DEPARTURE=20, DEPARTURE_TIME=18, DEPARTURE_DELAY=-2, TAXI_OUT=16, WHEELS_OFF=34, SCHEDULED_TIME=286, ELAPSED_TIME=293, AIR_TIME=266, DISTANCE=2296, WHEELS_ON=800, TAXI_IN=11, SCHEDULED_ARRIVAL=806, ARRIVAL_TIME=811, ARRIVAL_DELAY=5, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AA', FLIGHT_NUMBER=258, TAIL_NUMBER='N3HYAA', ORIGIN_AIRPORT='LAX', DESTINATION_AIRPORT='MIA', SCHEDULED_DEPARTURE=20, DEPARTURE_TIME=15, DEPARTURE_DELAY=-5, TAXI_OUT=15, WHEELS_OFF=30, SCHEDULED_TIME=285, ELAPSED_TIME=281, AIR_TIME=258, DISTANCE=2342, WHEELS_ON=748, TAXI_IN=8, SCHEDULED_ARRIVAL=805, ARRIVAL_TIME=756, ARRIVAL_DELAY=-9, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AS', FLIGHT_NUMBER=135, TAIL_NUMBER='N527AS', ORIGIN_AIRPORT='SEA', DESTINATION_AIRPORT='ANC', SCHEDULED_DEPARTURE=25, DEPARTURE_TIME=24, DEPARTURE_DELAY=-1, TAXI_OUT=11, WHEELS_OFF=35, SCHEDULED_TIME=235, ELAPSED_TIME=215, AIR_TIME=199, DISTANCE=1448, WHEELS_ON=254, TAXI_IN=5, SCHEDULED_ARRIVAL=320, ARRIVAL_TIME=259, ARRIVAL_DELAY=-21, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAk8Cuc60a-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455d7579-8d85-4727-e46f-fe85e712e616"
      },
      "source": [
        "# check first five rows v2\n",
        "spark_df.head(5)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AS', FLIGHT_NUMBER=98, TAIL_NUMBER='N407AS', ORIGIN_AIRPORT='ANC', DESTINATION_AIRPORT='SEA', SCHEDULED_DEPARTURE=5, DEPARTURE_TIME=2354, DEPARTURE_DELAY=-11, TAXI_OUT=21, WHEELS_OFF=15, SCHEDULED_TIME=205, ELAPSED_TIME=194, AIR_TIME=169, DISTANCE=1448, WHEELS_ON=404, TAXI_IN=4, SCHEDULED_ARRIVAL=430, ARRIVAL_TIME=408, ARRIVAL_DELAY=-22, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AA', FLIGHT_NUMBER=2336, TAIL_NUMBER='N3KUAA', ORIGIN_AIRPORT='LAX', DESTINATION_AIRPORT='PBI', SCHEDULED_DEPARTURE=10, DEPARTURE_TIME=2, DEPARTURE_DELAY=-8, TAXI_OUT=12, WHEELS_OFF=14, SCHEDULED_TIME=280, ELAPSED_TIME=279, AIR_TIME=263, DISTANCE=2330, WHEELS_ON=737, TAXI_IN=4, SCHEDULED_ARRIVAL=750, ARRIVAL_TIME=741, ARRIVAL_DELAY=-9, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='US', FLIGHT_NUMBER=840, TAIL_NUMBER='N171US', ORIGIN_AIRPORT='SFO', DESTINATION_AIRPORT='CLT', SCHEDULED_DEPARTURE=20, DEPARTURE_TIME=18, DEPARTURE_DELAY=-2, TAXI_OUT=16, WHEELS_OFF=34, SCHEDULED_TIME=286, ELAPSED_TIME=293, AIR_TIME=266, DISTANCE=2296, WHEELS_ON=800, TAXI_IN=11, SCHEDULED_ARRIVAL=806, ARRIVAL_TIME=811, ARRIVAL_DELAY=5, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AA', FLIGHT_NUMBER=258, TAIL_NUMBER='N3HYAA', ORIGIN_AIRPORT='LAX', DESTINATION_AIRPORT='MIA', SCHEDULED_DEPARTURE=20, DEPARTURE_TIME=15, DEPARTURE_DELAY=-5, TAXI_OUT=15, WHEELS_OFF=30, SCHEDULED_TIME=285, ELAPSED_TIME=281, AIR_TIME=258, DISTANCE=2342, WHEELS_ON=748, TAXI_IN=8, SCHEDULED_ARRIVAL=805, ARRIVAL_TIME=756, ARRIVAL_DELAY=-9, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None),\n",
              " Row(YEAR=2015, MONTH=1, DAY=1, DAY_OF_WEEK=4, AIRLINE='AS', FLIGHT_NUMBER=135, TAIL_NUMBER='N527AS', ORIGIN_AIRPORT='SEA', DESTINATION_AIRPORT='ANC', SCHEDULED_DEPARTURE=25, DEPARTURE_TIME=24, DEPARTURE_DELAY=-1, TAXI_OUT=11, WHEELS_OFF=35, SCHEDULED_TIME=235, ELAPSED_TIME=215, AIR_TIME=199, DISTANCE=1448, WHEELS_ON=254, TAXI_IN=5, SCHEDULED_ARRIVAL=320, ARRIVAL_TIME=259, ARRIVAL_DELAY=-21, DIVERTED=0, CANCELLED=0, CANCELLATION_REASON=None, AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHi7-Tcn0cxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee378a15-7f28-4c62-b4ed-3e1820239567"
      },
      "source": [
        "# check column datatypes\n",
        "spark_df.printSchema()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- YEAR: integer (nullable = true)\n",
            " |-- MONTH: integer (nullable = true)\n",
            " |-- DAY: integer (nullable = true)\n",
            " |-- DAY_OF_WEEK: integer (nullable = true)\n",
            " |-- AIRLINE: string (nullable = true)\n",
            " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
            " |-- TAIL_NUMBER: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
            " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
            " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
            " |-- DEPARTURE_TIME: integer (nullable = true)\n",
            " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
            " |-- TAXI_OUT: integer (nullable = true)\n",
            " |-- WHEELS_OFF: integer (nullable = true)\n",
            " |-- SCHEDULED_TIME: integer (nullable = true)\n",
            " |-- ELAPSED_TIME: integer (nullable = true)\n",
            " |-- AIR_TIME: integer (nullable = true)\n",
            " |-- DISTANCE: integer (nullable = true)\n",
            " |-- WHEELS_ON: integer (nullable = true)\n",
            " |-- TAXI_IN: integer (nullable = true)\n",
            " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
            " |-- ARRIVAL_TIME: integer (nullable = true)\n",
            " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
            " |-- DIVERTED: integer (nullable = true)\n",
            " |-- CANCELLED: integer (nullable = true)\n",
            " |-- CANCELLATION_REASON: string (nullable = true)\n",
            " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
            " |-- SECURITY_DELAY: integer (nullable = true)\n",
            " |-- AIRLINE_DELAY: integer (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
            " |-- WEATHER_DELAY: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4VRqnibQeHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00542096-cdc1-43a2-9387-32729dda6566"
      },
      "source": [
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "\n",
        "# check for nans in each column\n",
        "spark_df.select([count(when(isnan(c), c)).alias(c) for c in spark_df.columns]).show()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|   0|    0|  0|          0|      0|            0|          0|             0|                  0|                  0|             0|              0|       0|         0|             0|           0|       0|       0|        0|      0|                0|           0|            0|       0|        0|                  0|               0|             0|            0|                  0|            0|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-A-eMdicBOz",
        "outputId": "759a728f-3217-44cc-f685-58d7975128a7"
      },
      "source": [
        "# but NOT the same as nulls!\n",
        "spark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns]).show()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|   0|    0|  0|          0|      0|            0|      14721|             0|                  0|                  0|         86153|          86153|   89047|     89047|             6|      105071|  105071|       0|    92513|  92513|                0|       92513|       105071|       0|        0|            5729195|         4755640|       4755640|      4755640|            4755640|      4755640|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo1urp5e0iSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cc1d59-9965-41a9-b703-af69bf37330d"
      },
      "source": [
        "# can groupby\n",
        "spark_df.groupby('DAY_OF_WEEK').count().show()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+------+\n",
            "|DAY_OF_WEEK| count|\n",
            "+-----------+------+\n",
            "|          1|865543|\n",
            "|          6|700545|\n",
            "|          3|855897|\n",
            "|          5|862209|\n",
            "|          4|872521|\n",
            "|          7|817764|\n",
            "|          2|844600|\n",
            "+-----------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOnCa8LvNhQN"
      },
      "source": [
        "# only want certain columns\n",
        "spark_df = spark_df.select(col(\"MONTH\"),col(\"DAY_OF_WEEK\"), col(\"AIR_TIME\"), col('ARRIVAL_DELAY'))"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmn0b0HFNtWv",
        "outputId": "6e4a5b9d-5306-494d-df29-be28834601c8"
      },
      "source": [
        "spark_df.columns"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MONTH', 'DAY_OF_WEEK', 'AIR_TIME', 'ARRIVAL_DELAY']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0X_9U7WZ1gI",
        "outputId": "7a496995-407b-4e9d-e3e3-8457944770d9"
      },
      "source": [
        "spark_df.take(5)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=169, ARRIVAL_DELAY=-22),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=263, ARRIVAL_DELAY=-9),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=266, ARRIVAL_DELAY=5),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=258, ARRIVAL_DELAY=-9),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=199, ARRIVAL_DELAY=-21)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJl6Y6Yc_xh"
      },
      "source": [
        "# need to drop nulls in those columns\n",
        "spark_df = spark_df.na.drop(subset=[\"AIR_TIME\", \"ARRIVAL_DELAY\"])"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaaBpEkadgcc"
      },
      "source": [
        "Now - time to prep our target! Going to predict whether there was a delay in arrival or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAtU1sKuWm7U"
      },
      "source": [
        "def prep_target(delay_value):\n",
        "  if delay_value < 0: \n",
        "    return 0\n",
        "  else: \n",
        "    return 1"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsAW1tzdVAbo"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "# here, creating a User Defined Function, resulting in a boolean column\n",
        "udfTargetToCategory = udf(prep_target, IntegerType())\n",
        "\n",
        "preprocessed_df = spark_df.withColumn(\"delay_ind\", udfTargetToCategory(\"ARRIVAL_DELAY\"))\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ssc6SGQZYFE",
        "outputId": "798cb398-3f3d-473f-ee28-28570e380f84"
      },
      "source": [
        "preprocessed_df.take(5)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=169, ARRIVAL_DELAY=-22, delay_ind=0),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=263, ARRIVAL_DELAY=-9, delay_ind=0),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=266, ARRIVAL_DELAY=5, delay_ind=1),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=258, ARRIVAL_DELAY=-9, delay_ind=0),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=199, ARRIVAL_DELAY=-21, delay_ind=0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZP32-6gHrJX"
      },
      "source": [
        "Need to encode!\n",
        "\n",
        "https://spark.apache.org/docs/2.3.0/api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoderEstimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H3_8A0_0wC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bd0e27-2c8e-4abc-8b69-7046c0202abb"
      },
      "source": [
        "from pyspark.ml import feature\n",
        "\n",
        "ohe = feature.OneHotEncoderEstimator(inputCols=['MONTH', 'DAY_OF_WEEK'], \n",
        "                                     outputCols=['month_vec', 'day_vec'])\n",
        "ohe_hot_encoded = ohe.fit(preprocessed_df).transform(preprocessed_df)\n",
        "ohe_hot_encoded.head()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=169, ARRIVAL_DELAY=-22, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGxQKx8QZHFg",
        "outputId": "e04ead4d-683e-440c-8238-77de429f3235"
      },
      "source": [
        "ohe_hot_encoded.take(5)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=169, ARRIVAL_DELAY=-22, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=263, ARRIVAL_DELAY=-9, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=266, ARRIVAL_DELAY=5, delay_ind=1, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=258, ARRIVAL_DELAY=-9, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=199, ARRIVAL_DELAY=-21, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8smUojcU2Xi4"
      },
      "source": [
        "# only using a few of the features as inputs\n",
        "features = ['AIR_TIME', 'month_vec', 'day_vec']\n",
        "target = 'delay_ind'\n",
        "\n",
        "# need to vectorize the inputs\n",
        "vector = feature.VectorAssembler(inputCols = features, outputCol = 'features')\n",
        "vectorized_df = vector.transform(ohe_hot_encoded)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utOj9mKGNFn8",
        "outputId": "8ad4402e-11f3-49c5-af9a-152b5df8a3cc"
      },
      "source": [
        "print(type(vector))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.ml.feature.VectorAssembler'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3k4g2mRNLl-",
        "outputId": "535af7ec-ea4e-4d20-d191-0c5d62a51b74"
      },
      "source": [
        "vectorized_df.columns"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MONTH',\n",
              " 'DAY_OF_WEEK',\n",
              " 'AIR_TIME',\n",
              " 'ARRIVAL_DELAY',\n",
              " 'delay_ind',\n",
              " 'month_vec',\n",
              " 'day_vec',\n",
              " 'features']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRj2k8PMZAFu",
        "outputId": "00301926-b2cd-4ea5-9a72-d59d68363cdc"
      },
      "source": [
        "vectorized_df.take(5)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=169, ARRIVAL_DELAY=-22, delay_ind=False, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}), features=SparseVector(20, {0: 169.0, 2: 1.0, 17: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=263, ARRIVAL_DELAY=-9, delay_ind=False, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}), features=SparseVector(20, {0: 263.0, 2: 1.0, 17: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=266, ARRIVAL_DELAY=5, delay_ind=True, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}), features=SparseVector(20, {0: 266.0, 2: 1.0, 17: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=258, ARRIVAL_DELAY=-9, delay_ind=False, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}), features=SparseVector(20, {0: 258.0, 2: 1.0, 17: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=199, ARRIVAL_DELAY=-21, delay_ind=False, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}), features=SparseVector(20, {0: 199.0, 2: 1.0, 17: 1.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9LAYZE2YDfn"
      },
      "source": [
        "It appears I'm not alone in having trouble with `randomSplit`: https://medium.com/udemy-engineering/pyspark-under-the-hood-randomsplit-and-sample-inconsistencies-examined-7c6ec62644bc\n",
        "\n",
        "(I'll note, though, that my problems were not rooted in this issue!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB3qQn_s3ylX"
      },
      "source": [
        "# train test split\n",
        "# Implementing the solution discussed above\n",
        "\n",
        "persist_df = vectorized_df.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "train, test = persist_df.randomSplit([0.7, 0.3], seed = 11)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkc1NkeXOEpm",
        "outputId": "fd1579e8-1192-465c-e8da-3f639b57845e"
      },
      "source": [
        "type(train)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqk74er94BSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "623afc72-a66a-49e1-8339-556d37aa0a0b"
      },
      "source": [
        "train.take(5)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MONTH=1, DAY_OF_WEEK=1, AIR_TIME=9, ARRIVAL_DELAY=-25, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {1: 1.0}), features=SparseVector(20, {0: 9.0, 2: 1.0, 14: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=1, AIR_TIME=9, ARRIVAL_DELAY=-16, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {1: 1.0}), features=SparseVector(20, {0: 9.0, 2: 1.0, 14: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=1, AIR_TIME=13, ARRIVAL_DELAY=-9, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {1: 1.0}), features=SparseVector(20, {0: 13.0, 2: 1.0, 14: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=1, AIR_TIME=13, ARRIVAL_DELAY=31, delay_ind=1, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {1: 1.0}), features=SparseVector(20, {0: 13.0, 2: 1.0, 14: 1.0})),\n",
              " Row(MONTH=1, DAY_OF_WEEK=1, AIR_TIME=14, ARRIVAL_DELAY=-18, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {1: 1.0}), features=SparseVector(20, {0: 14.0, 2: 1.0, 14: 1.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Z7ztcH4CgX"
      },
      "source": [
        "# Now let's try a classifier!\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'delay_ind', \n",
        "                            maxDepth = 3)\n",
        "dtModel = dt.fit(train)\n",
        "predictions = dtModel.transform(test)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPNh5k5L4_ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a9dcac-38d0-4898-efab-82fababd668e"
      },
      "source": [
        " # Evaluate!\n",
        " from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        " evaluator = BinaryClassificationEvaluator(rawPredictionCol = 'prediction',\n",
        "                                           labelCol = 'delay_ind')\n",
        " evaluator.evaluate(predictions) # Note: ROC/AUC score"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHDTmAcF_Q8v"
      },
      "source": [
        "#### Evaluate! How'd we do? Why?\n",
        "\n",
        "- .5 ROC/AUC??? Guess: is our model only predicting a single class?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUOd_EsT57pU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19d5f72-f025-4eb6-d950-b927ebe42de6"
      },
      "source": [
        "# Explore our predictions\n",
        "predictions.groupby('prediction').count().show()\n",
        "# note - this is the size of the test set"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+\n",
            "|prediction|  count|\n",
            "+----------+-------+\n",
            "|       0.0|1713597|\n",
            "+----------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3kHOMi6M6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d9546b-d18b-473a-f95d-063e4b28ceba"
      },
      "source": [
        "# Explore our original data\n",
        "test.groupby('delay_ind').count().show()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-------+\n",
            "|delay_ind|  count|\n",
            "+---------+-------+\n",
            "|        1| 663602|\n",
            "|        0|1049995|\n",
            "+---------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHmC7F5siHX6",
        "outputId": "65bb0ce1-5728-4a0a-d058-dff4ffa6c1cc"
      },
      "source": [
        "preprocessed_df.groupby('delay_ind').count().show()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-------+\n",
            "|delay_ind|  count|\n",
            "+---------+-------+\n",
            "|        1|2213109|\n",
            "|        0|3500899|\n",
            "+---------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgMAMyocAiQ4"
      },
      "source": [
        "Yup - it is only predicting the majority class.\n",
        "\n",
        "How can we fix this? Let's try undersampling our majority so our classes are more balanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwE_j9uz6V0L"
      },
      "source": [
        "# Note that these don't use square brackets!\n",
        "major_df = preprocessed_df.filter(col('delay_ind') == 0)\n",
        "minor_df = preprocessed_df.filter(col('delay_ind') == 1)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTCyg7tH64kg"
      },
      "source": [
        "# Down-sample - without replacement\n",
        "sampled_majority_df = major_df.sample(False, .65)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIHzsSKl7MdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92055e03-f20b-4007-f9db-35d75a39fdde"
      },
      "source": [
        "sampled_majority_df.count()"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2274927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v4e4kic7N5d"
      },
      "source": [
        "combined_df = sampled_majority_df.unionAll(minor_df)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWkskNKl7W7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc69b83f-3b2b-4cf9-c145-52d6e987660e"
      },
      "source": [
        "combined_df.groupby('delay_ind').count().show()"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-------+\n",
            "|delay_ind|  count|\n",
            "+---------+-------+\n",
            "|        1|2213109|\n",
            "|        0|2274927|\n",
            "+---------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oeg6bcC87Z9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6efb416-1cf7-429e-f2f3-50d0c4dfc03b"
      },
      "source": [
        "combined_df.columns"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MONTH', 'DAY_OF_WEEK', 'AIR_TIME', 'ARRIVAL_DELAY', 'delay_ind']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQVhrJIJ7dxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270451f8-67a2-4a99-d732-0b3b224d5753"
      },
      "source": [
        "ohe = feature.OneHotEncoderEstimator(inputCols=['MONTH', 'DAY_OF_WEEK'], \n",
        "                                     outputCols=['month_vec', 'day_vec'])\n",
        "ohe_hot_encoded = ohe.fit(combined_df).transform(combined_df)\n",
        "ohe_hot_encoded.head()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(MONTH=1, DAY_OF_WEEK=4, AIR_TIME=169, ARRIVAL_DELAY=-22, delay_ind=0, month_vec=SparseVector(12, {1: 1.0}), day_vec=SparseVector(7, {4: 1.0}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nf9YZ6f7qeK"
      },
      "source": [
        "features = ['AIR_TIME', 'month_vec', 'day_vec']\n",
        "target = 'delay_ind'\n",
        "\n",
        "vector = feature.VectorAssembler(inputCols = features, outputCol = 'features')\n",
        "vectorized_df = vector.transform(ohe_hot_encoded)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FnD8zQd78Y0"
      },
      "source": [
        "persist_df = vectorized_df.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "train, test = persist_df.randomSplit([0.7, 0.3], seed = 11)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_yx7HUI70CO"
      },
      "source": [
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'delay_ind', \n",
        "                            maxDepth = 9)\n",
        "dtModel = dt.fit(train)\n",
        "predictions = dtModel.transform(test)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nWIJOJ75Lo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8c6773-94d8-40a5-9ea0-a6ad40f41dcd"
      },
      "source": [
        " evaluator = BinaryClassificationEvaluator(rawPredictionCol = 'prediction',\n",
        "                                           labelCol = 'delay_ind')\n",
        " evaluator.evaluate(predictions)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.542377707269281"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuT3KOCy_yU-"
      },
      "source": [
        "#### Evaluate!\n",
        "\n",
        "- \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V4QmB7D8fXp"
      },
      "source": [
        "# Other Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b03r-f18jMW"
      },
      "source": [
        "## Hadoop vs Spark: which is better?\n",
        "\n",
        "> Spark has been found to run 100 times faster in-memory, and 10 times faster on disk. Itâ€™s also been used to sort 100 TB of data 3 times faster than Hadoop MapReduce on one-tenth of the machines. Spark has particularly been found to be faster on machine learning applications, such as Naive Bayes and k-means. Spark performance, as measured by processing speed, has been found to be optimal over Hadoop, for several reasons:\n",
        "- Spark is not bound by input-output concerns every time it runs a selected part of a MapReduce task. Itâ€™s proven to be much faster for applications.\n",
        "- Sparkâ€™s DAGs enable optimizations between steps. Hadoop doesnâ€™t have any cyclical connection between MapReduce steps, meaning no performance tuning can occur at that level. However, if Spark is running on YARN with other shared services, performance might degrade and cause RAM overhead memory leaks. For this reason, if a user has a use-case of batch processing, Hadoop has been found to be the more efficient system.\n",
        "\n",
        "Using Hadoop and Spark together\n",
        "> There are several instances where you would want to use the two tools together. Despite some asking if Spark will replace Hadoop entirely because of the formerâ€™s processing power, they are meant to complement each other rather than compete"
      ]
    }
  ]
}